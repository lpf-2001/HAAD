[cnn]
model_type = CNN
nb_epochs = 30
maxlen = 200
batch_size = 128
train_ratio = 0.8
val_ratio = 0.1
test_ratio = 0.1
optimizer = rmsprop
[[adamax]]
learning_rate = 0.002
[[rmsprop]]
learning_rate = 0.00002
decay = 0
momentum = 0.001
[df]
model_type = DF
nb_epochs = 30
maxlen = 200
train_ratio = 0.6
val_ratio = 0.2
test_ratio = 0.2
batch_size = 256
optimizer = adamax
[[adamax]]
learning_rate = 0.002
[[rmsprop]]
learning_rate = 0.0015
decay = 0.001
momentum = 0.001
[awf]
model_type = AWF
nb_epochs = 30
maxlen = 200
train_ratio = 0.6
val_ratio = 0.2
test_ratio = 0.2
batch_size = 256
optimizer = adamax
[[adamax]]
learning_rate = 0.001
[[rmsprop]]
learning_rate = 0.0015
decay = 0.001
momentum = 0.001
[lstm]
model_type = LSTM
nb_epochs = 150
batch_size = 128
train_ratio = 0.8
val_ratio = 0.1
test_ratio = 0.1
optimizer = adamax
[[model_param]]
num_classes = 95
input_size = 1
hidden_size = 128
num_layers = 2
[[rmsprop]]
learning_rate = 0.00004
decay = 0
momentum = 0
[[adamax]]
learning_rate = 0.002
[sdae]
model_type = SDAE
nb_epochs = 40
batch_size = 128
train_ratio = 0.8
val_ratio = 0.1
test_ratio = 0.1
optimizer = sgd
nb_layers = 3 
nb_classes = 95
enc_activation = Tanh
dec_activation = ReLU
[[sgd]]
learning_rate = 0.001
momentum = 0.9
decay = 0.0
nesterov = True
[[rmsprop]]
learning_rate = 0.000015
decay = 0.001
momentum = 0.001
[[adamax]]
learning_rate = 0.002
momentum = 0.9
decay = 0.0
nesterov = True
[[1]]
in_dim = 200
out_dim = 1000
epochs = 30
batch_size = 128
dropout = 0.2
optimizer = sgd
enc_activation = Tanh
dec_activation = ReLU
[[[sgd]]]
learning_rate = 0.001
momentum = 0.9
decay = 0.0
[[[rmsprop]]]
learning_rate = 0.001
decay = 0.001
momentum = 0.001
[[[adamax]]]
learning_rate =  0.002
momentum = 0.9
decay = 0.0
[[2]]
in_dim = 1000
out_dim = 500
epochs = 30
batch_size = 128
dropout = 0.2
optimizer = sgd
enc_activation = Tanh
dec_activation = ReLU
[[[sgd]]]
learning_rate= 0.001
momentum = 0.9
decay = 0.0
[[[rmsprop]]]
learning_rate = 0.001
decay = 0.001
momentum = 0.001
[[[adamax]]]
learning_rate =  0.002
momentum = 0.9
decay = 0.0
[[3]]
in_dim = 500
out_dim = 300
epochs = 40
batch_size = 128
dropout = 0.2
optimizer = sgd
enc_activation = Tanh
dec_activation = ReLU
[[[sgd]]]
learning_rate = 0.001
momentum = 0.9
decay = 0.0
[[[adamax]]]
learning_rate =  0.002
[[[rmsprop]]]
learning_rate = 0.0015
decay = 0.001
momentum = 0.001
[ensemble]
model_type = ENSEMBLE
nb_epochs = 100
maxlen = 200
batch_size = 128
train_ratio = 0.6
val_ratio = 0.2
test_ratio = 0.2
optimizer = adamax
optimizer1 = adamax
optimizer2 = adamax
optimizer3 = rmsprop
[[adamax]]
learning_rate = 0.002
[[rmsprop]]
learning_rate = 0.000015
decay = 0.13
momentum = 0
[[sgd]]
learning_rate = 0.001
momentum = 0.9
decay = 0.0
nesterov = True
[varcnn]
model_type = VarCNN
nb_epochs = 30
train_ratio = 0.8
val_ratio = 0.1
test_ratio = 0.1
batch_size = 128
optimizer = adamax
[[adamax]]
learning_rate = 0.0002
[[rmsprop]]
learning_rate = 0.0001
decay = 0.1
momentum = 0.01


[MockingBird]
batch_size = 256
dataset = "Sirinam"
nb_epoch = 60
lr = 0.0012
val_ratio = 0.1
test_ratio = 0.1

[BLANKET]
batch_size = 32
start = 40
end = 60
step = 2

[Ant]
max_insert = 6
batch_size = 128
numant = 15
itermax = 100
val_ratio = 0.742
test_ratio = 0.25
patch_nums = 8
